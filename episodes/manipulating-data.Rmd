---
title: 'Data wrangling'
teaching: 10
exercises: 2
---

:::::::::::::::::::::::::::::::::::::: questions 

- What are the main `dplyr` verbs?
- How can I analyse data within groups?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Know how to use the main `dplyr` verbs
- Use `group_by()` to aggregate and manipulate within groups

::::::::::::::::::::::::::::::::::::::::::::::::


:::::::::::: challenge

## Do I need to do this lesson?

If you already have experience with `dplyr`, you can skip this lesson if you can answer all the following questions.

1. Load in the weather data from the `readr` and `readxl` 'do I need to do this lesson' challenge.  In the process, create a column called `file` that contains the filename for each row.
2. Create a column called `city` with the name of the city ('brisbane', or 'sydney').
3. What is the median minimum (`min_temp_c`) and maximum (`max_temp_c`) temperature in the observations for each city?
4. Count the number of days when there were more than 10 hours of sunshine (`sunshine_hours`) in each city.
5. A cold cloudy day is one where there were fewer than 10 hours of sunshine, and the maximum temperature was less than 15 degrees.  A hot sunny day is one where there were more than 10 hours of sunshine, and the maximum temperature was more than than 25 degrees.  Calculate the the mean relative humidity at 9am (`rel_humid_9am_pc`) and 3pm (`rel_humid_3pm_pc`) on days that were hot and sunny, cold and cloudy, or neither.
6. What is the mean maximum temperature on the 5 hottest days in each city?
7. Add a column ranking the days by minimum temperature for each city, where the coldest day for each is rank 1, the next coldest is rank 2, etc.
8. Generate a forecast for each city using the code below. If a cloudy day is one where there are 10 or fewer hours of sunshine, on how many days was the forecast accurate?


```{r}
library(lubridate)

# generate days
days <- seq(ymd('2022-11-01'),ymd('2022-11-29'), by = '1 day')

# forecast is the same in each city - imagine it's a country-wide forecast
forecast <- tibble(
  date = rep(days)
) %>% 
  # toss a coin
  mutate(forecast = sample(c("cloudy", "sunny"), size = n(), replace=TRUE))
```


::::::::::: solution

```{r}
# 1. Load in the weather data from the `readr` and `readxl` 'do I need to do this lesson' challenge

library(tidyverse)

wthr_path <- here::here("episodes", "data", c("weather_brisbane.csv", "weather_sydney.csv"))

# column types
col_types <- list(
  date = col_date(format="%Y-%m-%d"),
  min_temp_c = col_double(),
  max_temp_c = col_double(),
  rainfall_mm = col_double(),
  evaporation_mm = col_double(),
  sunshine_hours = col_double(),
  dir_max_wind_gust = col_character(),
  speed_max_wind_gust_kph = col_double(),
  time_max_wind_gust = col_time(),
  temp_9am_c = col_double(),
  rel_humid_9am_pc = col_integer(),
  cloud_amount_9am_oktas = col_double(),
  wind_direction_9am = col_character(),
  wind_speed_9am_kph = col_double(),
  MSL_pressure_9am_hPa = col_double(),
  temp_3pm_c = col_double(),
  rel_humid_3pm_pc = col_double(),
  cloud_amount_3pm_oktas = col_double(),
  wind_direction_3pm = col_character(),
  wind_speed_3pm_kph = col_double(),
  MSL_pressure_3pm_hPa = col_double()
)

# read in data
weather <- read_csv(wthr_path, skip=10, 
                    col_types=col_types, col_names = names(col_types),
                    id = "file"
                    )

glimpse(weather)

```

Nothing much new here if you already did the `readr` episode.

```{r}
# 2. Create a column with the name of the city ('brisbane', or 'sydney').

weather <- weather %>% 
  mutate(city = stringr::str_extract(file, "brisbane|sydney"))
```



```{r}
# 3. What is the median minimum (`min_temp_c`) and maximum (`max_temp_c`) 
# temperature in the observations for each city?

weather %>% 
  group_by(city) %>% 
  summarise(median_min_temp = median(min_temp_c),
            median_max_temp = median(max_temp_c, na.rm=TRUE))
```

We need `na.rm=TRUE` for the maximum column because this column contains `NA` values

```{r}
#4. Count the number of days when there were more than 10 hours of sunshine 
# (`sunshine_hours`) in each city.

weather %>% 
  mutate(sunny = sunshine_hours > 10) %>% 
  count(sunny, city)

```

Here I did `count()` as a shortcut for `group_by()` and `summarise()`, but the long way works too.


```{r}
#5. A cold cloudy day is one where there were fewer than 10 hours of sunshine, 
# and the maximum temperature was less than 15 degrees.  
# A hot sunny day is one where there were more than 10 hours of sunshine, 
# and the maximum temperature was more than than 25 degrees.  
# Calculate the the mean relative humidity at 9am (`rel_humid_9am_pc`) and 
# 3pm (`rel_humid_3pm_pc`) on days that were hot and sunny, cold and cloudy, or neither.

weather %>% 
  mutate(day = case_when(
    sunshine_hours > 10 & max_temp_c > 25 ~ "hot_sunny",
    sunshine_hours <= 10 & max_temp_c < 15 ~ "cold_cloudy",
    TRUE ~ "neither"
  )) %>% 
  group_by(day) %>% 
  summarise(mean_humid_9am = mean(rel_humid_9am_pc),
            mean_humid_3pm = mean(rel_humid_3pm_pc, na.rm=TRUE))
```

There were no cold cloudy days in this dataset.


```{r}
# 6. What is the mean maximum temperature on the 5 hottest days in each city?
weather %>% 
  group_by(city) %>% 
  slice_max(order_by = max_temp_c, n = 5, with_ties=FALSE) %>% 
  summarise(mean_max_temp = mean(max_temp_c, na.rm=TRUE))
```

Here I use `slice_max()`, but there are more complicated ways to solve this using other `dplyr` verbs.



```{r}
#7. Add a column ranking the days by minimum temperature for each city, 
# where the coldest day for each is rank 1, the next coldest is rank 2, etc.

weather %>% 
  group_by(city) %>% 
  arrange(min_temp_c) %>% 
  mutate(rank = row_number())
```

I tend to use the combination of `arrange()`, `mutate()` and `row_number()` for adding ranks, but there are probably other ways of achieving the same end.


```{r}
# 8.  If a cloudy day is one where there are 10 or fewer hours of sunshine, 
# on how many days was the forecast accurate?

weather %>% 
  left_join(forecast, by="date") %>% 
  mutate(cloudy_or_sunny = ifelse(sunshine_hours > 10, "sunny", "cloudy")) %>% 
  mutate(forecast_accurate = forecast == cloudy_or_sunny) %>% 
  count(forecast_accurate)
```

See challenge 7 for an alternative way of solving this problem.


::::::::::::::::::

:::::::::::::::::::::::

## Manipulating data with `dplyr`

So once we have our data in a tidy format, what do we do with it?  For analysis, I often turn to the `dplyr` package, which contains several useful functions for manipulating tables of data.

To illustrate the functions of this package, we'll use a dataset of weather observations in [Brisbane](http://www.bom.gov.au/climate/dwo/IDCJDW4019.latest.shtml) and Sydney from [the Bureau of Meterology](http://www.bom.gov.au/climate/dwo/index.shtml).

These files are called `weather_brisbane.csv` and `weather_sydney.csv`.

First, we load both files using `readr`:

```{r}
# load tidyverse
library(tidyverse)

# data files
# data files - readr can also read data from the internet
data_dir <- "https://raw.githubusercontent.com/szsctt/cmri_R_workshop/main/episodes/data/"
data_files <- file.path(data_dir, c("weather_sydney.csv", "weather_brisbane.csv"))


# column types
col_types <- list(
  date = col_date(format="%Y-%m-%d"),
  min_temp_c = col_double(),
  max_temp_c = col_double(),
  rainfall_mm = col_double(),
  evaporation_mm = col_double(),
  sunshine_hours = col_double(),
  dir_max_wind_gust = col_character(),
  speed_max_wind_gust_kph = col_double(),
  time_max_wind_gust = col_time(),
  temp_9am_c = col_double(),
  rel_humid_9am_pc = col_integer(),
  cloud_amount_9am_oktas = col_double(),
  wind_direction_9am = col_character(),
  wind_speed_9am_kph = col_double(),
  MSL_pressure_9am_hPa = col_double(),
  temp_3pm_c = col_double(),
  rel_humid_3pm_pc = col_double(),
  cloud_amount_3pm_oktas = col_double(),
  wind_direction_3pm = col_character(),
  wind_speed_3pm_kph = col_double(),
  MSL_pressure_3pm_hPa = col_double()
)

# read in data
weather <- readr::read_csv(data_files, skip=10, 
                           col_types=col_types, col_names = names(col_types),
                           id="file")
```

### Creating summaries with `summarise()`

First, we would like to know what the mean minimum and maximum temperatures were overall.  For this, we can use `summarise()`:

```{r}
weather %>% 
  summarise(mean_min_temp = mean(min_temp_c),
            mean_max_temp = mean(max_temp_c))
```

Notice that the mean_max_temp is `NA`, because we had some `NA` values in this column.  In `R` we use `NA` for missing values.  So how does one take the mean of some numbers, some of which are missing?  We can't so the answer is also a missing value.  We can, however, tell the `mean()` function to ignore the missing values using `na.rm=TRUE`:

```{r}
weather %>% 
  summarise(mean_min_temp = mean(min_temp_c),
            mean_max_temp = mean(max_temp_c, na.rm=TRUE))
```


::::::::::::::::: challenge


#### Challenge 1: medians

What is the median minimum and maximum temperature in the weather observations?

::::: solution


#### Show me the solution


```{r}
weather %>% 
  summarise(median_min_temp = median(min_temp_c),
            median_max_temp = median(max_temp_c, na.rm=TRUE))
```
::::::::::::::

:::::::::::::::::::::::::::


`dplyr` also has some special functions that are designed to be used inside of other functions.  For example, if we want to know how many observations there were of the minimum and maximum temperatures, we could use `n()`. Or if we wanted to know how many different directions the maximum wind gust had, we can use `n_distinct()`.

```{r}
weather %>% 
  summarise(n_days_observed = n(),
            n_wind_dir = n_distinct(dir_max_wind_gust))
```

#### Grouped summaries with `group_by()`

However, all of these summaries have combined the observations for Sydney and Brisbane. It probably makes sense to group the observations by city, and then compute the summary statistics.  For this, we can use `group_by()`.

If you use `group_by()` on a tibble, it doesn't actually look like it changes that much.

```{r}
weather %>% 
  group_by(file)
```

The only difference is that when you print it out, it tells you that it's grouped by file.  However, a grouped data frame interacts differently with other `dplyr` verbs, such as `summary`.

```{r}
weather %>% 
  group_by(file) %>% 
  summarise(median_min_temp = median(min_temp_c),
            median_max_temp = median(max_temp_c, na.rm=TRUE))
```

Now we get the median temperature for both Sydney and Brisbane.

:::::::::::::::: challenge


#### Challenge 2: medians

What is the maximum wind speed (`speed_max_wind_gust_kph`) in each direction (`dir_max_wind_gust`) for each city?

::::: solution


#### Show me the solution


```{r}
weather %>% 
  group_by(file, dir_max_wind_gust) %>% 
  summarise(max_max_wind_gust = max(speed_max_wind_gust_kph))
```
::::::::::::::

Can you pivot the table wider to make it easier to compare between directions and cities?

::::: solution

#### Show me the solution

```{r}
weather %>% 
  group_by(file, dir_max_wind_gust) %>% 
  summarise(max_max_wind_gust = max(speed_max_wind_gust_kph)) %>% 
  ungroup() %>% 
  pivot_wider(id_cols=file, names_from = "dir_max_wind_gust", values_from = "max_max_wind_gust")
```

Do you prefer the long or wide form of the table?

::::::::::::::

:::::::::::::::::::::::::::


### Creating new columns with `mutate()`

It's kind of annoying that we have the whole file names, rather than just the names of the cities.  To fix this, we can create (or overwrite) columns with `mutate()`.  

![`dplyr::mutate()` [image credit](https://ab604.github.io/docs/coding-together-2019)](https://ab604.github.io/docs/coding-together-2019/img/dplyr-mutate-16-10-2019.png)

For example, the `stringr::str_extract()` function extracts a matching pattern from a string:

```{r}
stringr::str_extract(data_files, "sydney|brisbane")
```

::::::::::: callout

### Regular expressions for pattern matching in strings 

The second argument to `str_extract()` is a regular expression, or *regex*.  Using regular expressions is a hugely flexible way to specify a pattern to match in a string, but it's a somewhat complicated topic that I won't go into here.  If you're interested in learning more, you can look at the [stringr documentation on regular expressions](https://stringr.tidyverse.org/articles/regular-expressions.html).

::::::::::::::::::


We can use `mutate()` to apply the `str_extract()` function to the `file` column

```{r}
weather <- weather %>% 
  mutate(city = stringr::str_extract(file, "sydney|brisbane"))
weather
```

Now if we repeat the same summary as before, we get an output that's a bit easier to read.

```{r}
weather %>% 
  group_by(city) %>% 
  summarise(median_min_temp = median(min_temp_c),
            median_max_temp = median(max_temp_c, na.rm=TRUE))
```


#### Mutating multiple columns with `across()`

Let's imagine that the calibration was wrong for both temperature sensors, and all the temperature measurements are out by 1Â°C.  We'd like to add 1 to each of the temperature measurements. There are multiple columns that contain temperatures, so we could do this:

```{r}
weather %>% 
  mutate(min_temp_c = min_temp_c + 1,
         max_temp_c = max_temp_c + 1,
         temp_9am_c = temp_9am_c + 1,
         temp_3pm_c = temp_3pm_c + 1) 
```


But it's a bit annoying to type out each column.  Instead, we can use `across()` inside `mutate()` to apply the same transformation to all columns whose name contains the string "temp".  The syntax is a little complicated, so don't worry if you don't get it straight away.  We use the `contains()` function to get the columns we want (by matching the regex "temp"), and then to each of these columns we add one - the `.` will be replaced by the name of each column when the expression is evaluated.


```{r}
weather %>% 
  mutate(across(contains("temp"), ~.+1))
```

Equivalently, we could also use a function to make the transformation.

```{r}
weather %>% 
  mutate(across(contains("temp"), function(x){
    return(x+1)
  }))
```

### Filtering rows with `filter()`

Let's say that now we want information about days that were cloudy - for example, those where there were fewer than 10 sunshine hours.  We can use `filter()` to get only those rows.


![`dplyr::filter()` [image credit](https://ab604.github.io/docs/coding-together-2019)](https://ab604.github.io/docs/coding-together-2019/img/dplyr_filter.png)

```{r}
weather %>% 
  filter(sunshine_hours < 10)
```


::::::::::::: challenge


#### Challenge 3: Is it better to live in Sydney or Brisbane?

Combine `filter()` with `group_by()`,`summarise()` and `n()` to count the number of days when there were more than 10 hours of sunshine in each city.

::::::::: solution

```{r}
weather %>% 
  filter(sunshine_hours > 10) %>% 
  group_by(city) %>% 
  summarise(n_days = n())
```

There were more days with more than 10 hours of sunlight in Brisbane than in Sydney.  I'll let you draw your own conclusions.

::::::::::::::::::

:::::::::::::::::::::::

#### Complex filters with `case_when()`

Let's say we wanted to keep only the rows from sunny, warm days and cloudy, cold days.  We could do this just with one logical expression.

```{r}
weather %>% 
  filter((sunshine_hours > 10 & max_temp_c > 25) | (sunshine_hours < 10 & max_temp_c < 15))
```

But you can imagine that with more conditions, this can get a bit messy.  I prefer to use `case_when()` in such situations:

```{r}
weather %>% 
  filter(case_when(
    sunshine_hours > 10 & max_temp_c > 25 ~ TRUE,
    sunshine_hours < 10 & max_temp_c < 15 ~ TRUE,
    TRUE ~ FALSE
  ))
```

Essentially, `case_when()` looks at each condition in turn, and if the left part of the expression (before the `~`) evaluates to `TRUE`, then it returns whatever is on the right of the `~`.  

 - We first ask if this row has more than ten sunshine hours and a maximum temperature of more than 25 - if this is the case, we return `TRUE` (and `filter()` retains this row).  
 - Next, we ask if the row has less than ten sunshine hours and a maximum temperature of less than 15, in which case we also return `TRUE`.  
 - If both these statements are `FALSE`, then the `TRUE` on the next line ensures that we don't keep those rows by always returning `FALSE`.


::::::::::::: challenge

#### Challenge 4: Using `case_when()` with `mutate()`

`case_when()` is also quite useful in combination with `mutate()`.  

For example, let's suppose you want to compare the mean relative humidity on about cloudy cold days and sunny hot days. 

You can first use `mutate()` and `case_when()` to create a column that tells which of these categories the day belongs to (`hot_sunny`, `cold_cloudy`, or `neither`), and then use `group_by()` and `summarise()` to get the mean relative humidity at 9am and 3pm.

Write the code to compute this.

::::::::: solution


```{r}
weather %>% 
  mutate(day_type = case_when(
    sunshine_hours > 10 & max_temp_c > 25 ~ "hot_sunny",
    sunshine_hours < 10 & max_temp_c < 15 ~ "cold_cloudy",
    TRUE ~ "neither"
  )) %>% 
  group_by(day_type) %>% 
  summarise(mean_rel_humid_9am = mean(rel_humid_9am_pc, na.rm=TRUE),
            mean_rel_humid_3pm = mean(rel_humid_3pm_pc, na.rm=TRUE))
```

Notice that we didn't actually have any cold cloudy days, but hot sunny days seem to be less humid.

::::::::::::::::::

:::::::::::::::::::::::


#### Filter within groups with `slice_xxx()`

There are three `slice` functions that you can use to filter your data: `slice_min()`, `slice_max()` and `slice_sample()`.  I usually use them together with `group_by()` to filter within groups.

use `slice_max()`

```{r}
weather %>% 
  group_by(city) %>% 
  slice_max(order_by=max_temp_c, n=1)
```

If you want the minimum values instead, use `slice_min()` and if you want a random sample, use `slice_sample()`.



::::::::::::: challenge

#### Challenge 5: Hottest days


What is the mean maximum temperature on the 5 hottest days in each city?

::::::::: solution


```{r}
weather %>% 
  group_by(city) %>% 
  # use with_ties to ensure we only get five rows
  slice_max(order_by=max_temp_c, n=5, with_ties = FALSE) %>% 
  summarise(
    mean_temp = mean(max_temp_c)
  )
```

Ooof, Brisbane was hot!  Maybe this changes your conclusion about which city is better.

::::::::::::::::::

:::::::::::::::::::::::



### Selecting columns with `select()`

If you want to drop or only retain columns from your table, use `select()`.

![`dplyr::select()` [image credit](https://ab604.github.io/docs/coding-together-2019)](https://ab604.github.io/docs/coding-together-2019/img/dplyr_select.png)

For example, we added a `city` column to our table, so we can drop the `file` column that also contains this information.  

```{r}
weather %>% 
  select(-file)
```

Alternatively, if we only wanted to keep the date, city and the 3pm observations, we can do this as well.

```{r}
weather %>% 
  select(date, city, contains("3pm"))
```

### Sorting rows with `arrange()`

You can re-order the rows in a table by the values in one or more columns using `arrange()`.

![`dplyr::arrange()` [image credit](https://ab604.github.io/docs/coding-together-2019)](https://ab604.github.io/docs/coding-together-2019/img/dplyr_arrange.png)
Here I sort for the hottest days, using `desc()` to get the maximum temperatures in descending order.


```{r}
weather %>% 
  arrange(desc(max_temp_c))
```



::::::::::::: challenge

#### Challenge 6: Using `arrange()` with `mutate()`

Sometimes I use `arrange()` with `mutate()` and `row_number()` to add ranks to a table.

Add a column ranking the days by minimum temperature for each city, where the coldest day for each is rank 1, the next coldest is rank 2, etc.

::::::::: solution


```{r}
weather %>% 
  group_by(city) %>% 
  arrange(min_temp_c) %>% 
  mutate(rank = row_number()) %>% 
  # select only the relevant columns to verify that it worked
  select(city, date, min_temp_c, rank)
```

::::::::::::::::::

:::::::::::::::::::::::



### Joining data frames

So far, we've only dealt with methods that work on one data frame.  Sometimes it's useful to combine information from two tables together to get a more complete picture of the data.

There are several joining functions, which fall into two categories: 

- [mutating joins](https://dplyr.tidyverse.org/reference/mutate-joins.html), which add extra columns to tables based on matching values
- [filtering joins](https://dplyr.tidyverse.org/reference/filter-joins.html), which don't add extra columns but change the number of rows

Here, I'll only cover the join I use the most, `left_join()`, but there are several joins of each type, which I will leave to you to explore more using the links above.

![left join](https://ab604.github.io/docs/coding-together-2019/img/left_join.png)

Let's say we have a second table which contains the forecast for each day.  Here I generate this randomly, but you could equally use `readr` or `readxl` to load this data in if you have it in a file.

```{r}
forecast <- weather %>% 
  select(date, city) %>% 
  mutate(forecast = sample(c("cloudy", "sunny"), size = n(), replace=TRUE))

forecast
```

Now we would like to join this to our data frame of observations, so we can compare the forecast to what actually happened.

```{r}
weather %>% 
  left_join(forecast, by=c("date", "city")) %>% 
  select(city, date, sunshine_hours, forecast)
```



::::::::::::: challenge

#### Challenge 7: [Blame it on the weatherman](https://www.youtube.com/watch?v=t2UFV2R3EZM)

If a cloudy day is one where there are 10 or fewer hours of sunshine, on how many days was the forecast accurate?


::::::::: solution


```{r}
weather %>% 
  # join forecast information
  left_join(forecast, by=c("date", "city")) %>% 
  # was forecast accurate
  mutate(forecast_accurate = case_when(
    sunshine_hours > 10 & forecast == "sunny" ~ TRUE,
    sunshine_hours <= 10 & forecast == "cloudy" ~ TRUE,
    TRUE ~ FALSE
  )) %>%
  # count accurate and inaccurate forecasts
  group_by(forecast_accurate) %>% 
  summarise(count = n())
```

::::::::::::::::::

:::::::::::::::::::::::

## Working with large tables

`dplyr` works well if you have small tables, but when they get large (millions of rows), you might start to notice that your code takes a while to execute.  If you start to notice this is an issue (and not before), I'd recommend you check out the `dtplyr` package](https://dtplyr.tidyverse.org/), which translates `dplyr` verbs into code used by another, faster package called `data.table`.

Of course, you could also [just learn the `data.table` package](https://rdatatable.gitlab.io/data.table/) and use it directly.


## Resources and acknowlegements

 - [dplyr cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf)
 - [dplyr documentation](https://dplyr.tidyverse.org/)
 - [Data transformation in R for data science](https://r4ds.had.co.nz/transform.html)
 - I've borrowed figures (and inspiration) from the excellent [coding togetheR course material](https://ab604.github.io/docs/coding-together-2019/data-wrangle-1.html)


::::::::::::::::::::::::::::::::::::: keypoints 

- Use `summarise()` to summarise your data
- Use `mutate()` to add new columns
- Use `filter()` to filter rows by a condition
- Use `select()` to remove or only retain certain rows
- Use `arrange()` to re-order rows
- Use `group_by()` to group data by the values in particular columns
- Use joins to combine two data frames

::::::::::::::::::::::::::::::::::::::::::::::::

